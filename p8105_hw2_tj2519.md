p8105_hw2_tj2519
================
2023-09-30

``` r
library(tidyverse)
library(readxl)
```

# Problem 1 - process the pols-month, snp, unemployment dataset

## processing the datasets

``` r
pols_df = 
  read_csv("data/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, c("year", "month", "day"), "-", convert = TRUE) %>% 
  mutate(month = ifelse(month == 1, "jan", month),
         month = ifelse(month == 2, "feb", month),
         month = ifelse(month == 3, "mar", month),
         month = ifelse(month == 4, "apr", month),
         month = ifelse(month == 5, "may", month),
         month = ifelse(month == 6, "jun", month),
         month = ifelse(month == 7, "jul", month),
         month = ifelse(month == 8, "aug", month),
         month = ifelse(month == 9, "sep", month),
         month = ifelse(month == 10, "oct", month),
         month = ifelse(month == 11, "nov", month),
         month = ifelse(month == 12, "dec", month)
         ) %>% 
  mutate(president = ifelse(prez_gop == 1, "gop", "dem")) %>% 
  select(-day, -starts_with("prez"))

print(sapply(pols_df, class))
##        year       month     gov_gop     sen_gop     rep_gop     gov_dem 
##   "integer" "character"   "numeric"   "numeric"   "numeric"   "numeric" 
##     sen_dem     rep_dem   president 
##   "numeric"   "numeric" "character"
view(pols_df)


snp_df = 
  read_csv("data/snp.csv") %>% 
  janitor::clean_names() %>% 
  mutate(date = as.Date(date, format = "%m/%d/%y")) %>% 
  separate(date, c("year", "month", "day"), "-") %>% 
  mutate(year = as.numeric(year), month = as.numeric(month)) %>% 
  mutate(year = ifelse(year > as.integer(format(Sys.Date(), "%Y")), 
                       year - 100, year)) %>% 
  arrange(year, month) %>% 
  mutate(month = ifelse(month == 1, "jan", month),
         month = ifelse(month == 2, "feb", month),
         month = ifelse(month == 3, "mar", month),
         month = ifelse(month == 4, "apr", month),
         month = ifelse(month == 5, "may", month),
         month = ifelse(month == 6, "jun", month),
         month = ifelse(month == 7, "jul", month),
         month = ifelse(month == 8, "aug", month),
         month = ifelse(month == 9, "sep", month),
         month = ifelse(month == 10, "oct", month),
         month = ifelse(month == 11, "nov", month),
         month = ifelse(month == 12, "dec", month)
         ) %>%
  select(-day)
  


unemployment_df = 
  read_csv("data/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "percent"
  )

print(sapply(unemployment_df, class))  
##        year       month     percent 
##   "numeric" "character"   "numeric"
view(unemployment_df)
```

## left join the datasets

``` r
data_join = left_join(pols_df, snp_df) %>% 
  left_join(., unemployment_df)
```

# Problem 2

## part1 - read, clean and create the new weight_tons variable in the Mr. Trash Wheel sheet

``` r
trawh_df = 
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                     sheet = "Mr. Trash Wheel", range = "A2:N586") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(homes_powered = weight_tons * 500) %>% 
  mutate(wheel_type = "mr_trashwheel") %>% 
  relocate(wheel_type)
```

## part2 - read, clean and create the new weight_tons variable in the Professor Trash Wheel sheet

``` r
prof_trawh_df = 
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                     sheet = "Professor Trash Wheel", range = "A2:M109") %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>% 
  mutate(homes_powered = weight_tons * 500) %>% 
  mutate(wheel_type = "prof_trashwheel") %>% 
  relocate(wheel_type)
```

## part3 - read, clean and create the new weight_tons variable in the Gwynndal sheet

``` r
gwy_trawh_df = 
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                     sheet = "Gwynnda Trash Wheel", range = "A2:L159") %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>% 
  mutate(homes_powered = weight_tons * 500) %>% 
  mutate(wheel_type = "gwy_trashwheel") %>% 
  relocate(wheel_type) %>% 

view(gwy_trawh_df) 
```

## part 4 - combine the datasets

``` r
trawh_df_char = lapply(trawh_df, as.character)
prof_trawh_df_char = lapply(prof_trawh_df, as.character)
gwy_trawh_df_char = lapply(gwy_trawh_df, as.character)

trawhl_comb = bind_rows(trawh_df_char, prof_trawh_df_char, gwy_trawh_df_char)
```

The final dataset trawhl_comb contains 845 observations and it contains
15 variables. It also tells use in one specific date, a type of
trashwheel collect how many of each type of trash and the power used in
each day. As for the Mr. Trashwheel, the data is collected between 2014
and 2023. As for Professor Trash Wheel, the data is collected between
2017 and 2023. As for Gwynnda, the data is collected between 2021 and
2023. In the Professor Trash Wheel dataset, the total weight of trash
collected by Professor Trash Wheel is 216.26 tons. In the Gwynndal, the
total number of cigarette butts collected in July of 2021 is *1.63^{4}*.

# Problem 3

## part1 - import and clean-up the baseline dataset, we import and skip the first row of the original dataset. And then clean the names of all variables in the dataset. Also recode the apoe4 and sex variable in mci_baseline. Also get rid of the unqualified participants by using the “filter” function.

``` r
mci_demo = 
  read_csv("data_mci/MCI_baseline.csv", skip = 1) %>% 
  janitor::clean_names() %>% 
  mutate(sex = recode(sex, `0` = "female", `1` = "male"),
        apoe4 = recode(apoe4, `0` = "non-carrier", `1` = "carrier")) %>% 
  filter(age_at_onset == "." | current_age < age_at_onset)
  
　

count(filter(mci_demo, apoe4 == "carrier" & sex == "female")) / count(filter(mci_demo, sex == "female"))
##     n
## 1 0.3
```

Based on the dataset, 479 qualified participants are recruited into the
study, and 93 of them develop MCI during the study period. The average
baseline age is 65.03 years old. 30% of the females in this study are
APOE4 carriers.

## part2 - import and clean-up the mci_amyloid dataset, we import and skip the first row of the original dataset. And then clean the names of all variables in the dataset. Then, as the original baseline variable contains some N/A values, we would want to remove them from the dataset.

``` r
mci_amy = 
  read_csv("data_mci/mci_amyloid.csv", skip = 1) %>% 
  janitor::clean_names() %>% 
  rename(id = study_id) %>% 
  mutate(baseline = as.numeric(baseline), 
         time_2 = as.numeric(time_2),
         time_4 = as.numeric(time_4),
         time_6 = as.numeric(time_6),
         time_8 = as.numeric(time_8)) %>% 
  drop_na(baseline)
## Warning: There were 5 warnings in `mutate()`.
## The first warning was:
## ℹ In argument: `baseline = as.numeric(baseline)`.
## Caused by warning:
## ! NAs introduced by coercion
## ℹ Run `dplyr::last_dplyr_warnings()` to see the 4 remaining warnings.
```

## part3 - firstly, anti_join the two datasets to see whether there are some observations only existing in only one dataset. Also, combine the datasets containing only the observations existing in both original datasets

``` r
ad_demo_no_match = anti_join(mci_demo, mci_amy, by = "id")
ad_amy_no_match = anti_join(mci_amy, mci_demo, by = "id")

ad_both = inner_join(mci_demo, mci_amy, by = "id")

write_csv(ad_both, "data_mci/combined_data.csv")
```

The combinded dataset ad_both contains the participants in both of the
original dataset. It contains 470 participants and it involves 11
variables. Among all the participants, the mean current age is 65.04,
the mean baseline ratio of β42/40 is 0.11. As the time progress, there
are some N/A values appear, which might indicate that there are some
loss-of-followup participants during the study period. At the last time
points (time_8), the average β42/40 is 0.11 if ignoring the N/A values.
